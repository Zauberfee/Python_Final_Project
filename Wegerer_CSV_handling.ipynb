{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e33b94-290b-482e-a24b-39f74c8079e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Python - Final Project\n",
    "Author: Sebastian Wegerer<br>\n",
    "MatrNr: 01616960\n",
    "\n",
    "### Project:\n",
    "Data Structures and Data Management - Project\n",
    "\n",
    "People burried at St. Marx cemetery. \n",
    "\n",
    "### Content:\n",
    "\n",
    "1) Import source(s)\n",
    "2) Search for matches\n",
    "3) GeoCoder\n",
    "4) Sort csv(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d2b170-ef82-4857-b2a1-d12b39551935",
   "metadata": {},
   "source": [
    "## 1) Import source(s)\n",
    "\n",
    "\n",
    "CSV files contains several people buried at St_Marx. Different sources could contain bits of information. The idea of this notebook is to create a tool to process and manage the data automatically. \n",
    "\n",
    "First source: austriasites\n",
    "One big block of text copied to a txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1417c7da-cf41-4c6f-ab86-6c21477dda2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "#source:\n",
    "#https://www.austriasites.com/vienna/bezirk03_friedhof_st_marx_graeber.htm\n",
    "\n",
    "source_austriasites = ''\n",
    "\n",
    "with open('austriasites.txt') as l_reader:\n",
    "    source_austriasites = l_reader.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d441d2f-ff39-41c7-8abb-e6cd818ffd74",
   "metadata": {},
   "source": [
    "Creates a cleaned version of the original csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c19648-db00-4341-9043-d7496be11153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open(\"St_Marxer_Spreadsheet.csv\", \"r\")\n",
    "\n",
    "v_df_people = pd.DataFrame(pd.read_csv(\"St_Marxer_Spreadsheet.csv\", sep=\";\"))\n",
    "\n",
    "v_df_people.to_csv(\"St_Marxer_Spreadsheet_Cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455c9fe-4daa-4ae1-b0f9-c237fef8dc1d",
   "metadata": {},
   "source": [
    "## 2) Search for matches\n",
    "\n",
    "A loop searches for every single name from the list in the txt file from above. \n",
    "\n",
    "Names found are added to a data frame and saved as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919e1830-5a8c-41fb-a68d-2a14a78774ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_people = pd.DataFrame(pd.read_csv(\"St_Marxer_Spreadsheet_Cleaned.csv\", sep=\",\"))\n",
    "\n",
    "v_df_findings = pd.DataFrame()\n",
    "\n",
    "v_row_counter = 1\n",
    "\n",
    "for index in v_df_people.index:\n",
    "    \n",
    "    l_occurences = re.findall(v_df_people['varchar Name'][index], source_austriasites)\n",
    "    \n",
    "    if l_occurences != []:\n",
    "        \n",
    "        \n",
    "        v_df_findings.loc[v_row_counter, 'varchar Name'] = l_occurences[0]\n",
    "        v_row_counter = v_row_counter + 1     \n",
    "        \n",
    "        \n",
    "# index=False excludes the index we used to keep track of (row_counter)        \n",
    "v_df_findings.to_csv(\"Pemmer_Works_Matches.csv\", index=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfd043d-925c-47a1-90ad-f11de376b639",
   "metadata": {},
   "source": [
    "## 2 -a) Find everything\n",
    "\n",
    "There is more data to collect than the name. Regex is used to search for names but includes everything until a new line is detected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17031ec-1cf0-41b9-9fa7-34cf493ccc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_people = pd.DataFrame(pd.read_csv(\"St_Marxer_Spreadsheet.csv\", sep=\";\"))\n",
    "\n",
    "v_df_findings = pd.DataFrame()\n",
    "\n",
    "v_row_counter = 1\n",
    "\n",
    "for index in v_df_people.index:\n",
    "    \n",
    "    l_search_string = v_df_people['varchar Name'][index] + \".*\\n\"\n",
    "    \n",
    "    l_occurences = re.findall(l_search_string, source_austriasites)\n",
    "    \n",
    "    if l_occurences != []:\n",
    "        \n",
    "        v_df_findings.loc[v_row_counter, 'varchar Data'] = l_occurences[0]\n",
    "        v_row_counter = v_row_counter + 1     \n",
    "        \n",
    "        \n",
    "# index=False excludes the index we used to keep track of (row_counter)        \n",
    "v_df_findings.to_csv(\"Pemmer_Works_Data.csv\", index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7ee96-0d7d-4514-82f2-99c220cb383b",
   "metadata": {},
   "source": [
    "### Resulting problem:\n",
    "\n",
    "Data like this can't be used. Some sort of processing necessary!\n",
    "\n",
    "<img src=\"Pemmer_Problem.png\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341da041-0e9a-49e7-a2ec-206cfd020422",
   "metadata": {},
   "source": [
    "First attempt: split everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb7afd49-488a-48da-bf99-29cc78b748e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_data = pd.DataFrame(pd.read_csv(\"Pemmer_Works_Data.csv\", sep=\",\"))\n",
    "\n",
    "v_df_reworked = pd.DataFrame()\n",
    "\n",
    "\n",
    "for index in v_df_data.index:\n",
    "    l_fields = v_df_data.loc[index, 'varchar Data'].split(\",\")\n",
    "    \n",
    "    for element in l_fields:\n",
    "        v_df_reworked.loc[index, 'column: ' + str(l_fields.index(element))] = element\n",
    "\n",
    "v_df_reworked.to_csv(\"Pemmer_Works_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512c7bf-d17d-4a6c-ab79-1fb9bff6d821",
   "metadata": {},
   "source": [
    "## column: 0 \n",
    "\n",
    "The names can be used but everything else is out of order. Slower attempt needed!\n",
    "\n",
    "<img src=\"Pemmer_Problem_2.png\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c4662-bdaa-4382-9000-11f9d7f05fce",
   "metadata": {},
   "source": [
    "## <mark>--->>^ execute: 2 a-) Find everything ^<<---</mark>\n",
    "\n",
    "Separates the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c433ee0c-08e8-46da-a285-89edc9e1fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_data = pd.DataFrame(pd.read_csv(\"Pemmer_Works_Data.csv\", sep=\",\"))\n",
    "\n",
    "v_df_reworked = pd.DataFrame()\n",
    "\n",
    "\n",
    "for index in v_df_data.index:\n",
    "    l_fields = v_df_data.loc[index, 'varchar Data'].split(\",\", 1)\n",
    "    \n",
    "    v_df_reworked.loc[index, 'varchar Name'] = l_fields[0]\n",
    "    \n",
    "    if len(l_fields) > 1:\n",
    "        v_df_reworked.loc[index, 'varchar Data'] = l_fields[1]\n",
    "\n",
    "v_df_reworked.to_csv(\"Pemmer_Works_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61613c-3224-4e82-b97d-9c607e46568e",
   "metadata": {},
   "source": [
    "Separates the maiden name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4881953-5d7c-4f76-83fa-c2d2ff19679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_data = pd.DataFrame(pd.read_csv(\"Pemmer_Works_Data.csv\", sep=\",\"))\n",
    "\n",
    "v_df_reworked = v_df_data\n",
    "\n",
    "\n",
    "for index in v_df_data.index:\n",
    "\n",
    "    # Regex is not precise but works for the data\n",
    "    if v_df_data.loc[index].str.contains('geb.', case=True, regex=True)[1] == True:\n",
    "        l_row = v_df_data.loc[index, 'varchar Data']\n",
    "        l_row = l_row.split(\",\", 1)\n",
    "        \n",
    "        \n",
    "        v_df_reworked.loc[index, 'varchar Maiden_Name'] = l_row[0].split(\" \")[-1]\n",
    "        v_df_reworked.loc[index, 'varchar Data'] = l_row[1]\n",
    "    \n",
    "    if v_df_data.loc[index].str.contains('\\d\\d\\.\\d\\d\\.\\d\\d\\d\\d.*\\d\\d\\.\\d\\d\\.\\d\\d\\d\\d', case=True, regex=True)[1] == True:\n",
    "        l_row = v_df_data.loc[index, 'varchar Data']\n",
    "\n",
    "v_df_reworked.to_csv(\"Pemmer_Works_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b2cb18-311e-4809-9eb4-378ca5690bdd",
   "metadata": {},
   "source": [
    "Merges the found and prepared data with the original data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b0f51f-3331-486f-b318-2742bf7890d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_df_data = pd.DataFrame(pd.read_csv(\"St_Marxer_Spreadsheet_Cleaned.csv\", sep=\",\"))\n",
    "v_df_source = pd.DataFrame(pd.read_csv(\"Pemmer_Works_Data.csv\", sep=\",\"))\n",
    "\n",
    "\n",
    "v_df_merged = pd.merge(\n",
    "    v_df_data,\n",
    "    v_df_source,\n",
    "    how=\"left\",\n",
    "    on=None,\n",
    "    left_on=None,\n",
    "    right_on=None,\n",
    "    left_index=False,\n",
    "    right_index=False,\n",
    "    sort=True,\n",
    "    suffixes=(\"_x\", \"_y\"),\n",
    "    copy=True,\n",
    "    indicator=False,\n",
    "    validate=None,\n",
    ")\n",
    "\n",
    "v_df_merged.to_csv(\"Merged.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad91124e-57a8-474d-992f-45a3a427383a",
   "metadata": {},
   "source": [
    "## 3) GeoCoder\n",
    "\n",
    "Looks up coordinates for addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dfd8a51-d54b-4d64-9059-07778ed96961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Exit with: -1- or enter the address you would like to check:  Ringstrasse 1\n",
      "Skip with: -2- or enter name to attach:  Carl Khym\n",
      "Exit with: -1- or enter the address you would like to check:  Rathausplatz 1\n",
      "Skip with: -2- or enter name to attach:  Superman\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning E05: No one found with the name: Superman. Coords for: Rathausplatz 1 are not saved!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Exit with: -1- or enter the address you would like to check:  Rathausplatz 1\n",
      "Skip with: -2- or enter name to attach:  2\n",
      "Exit with: -1- or enter the address you would like to check:  1\n"
     ]
    }
   ],
   "source": [
    "import geopy.geocoders as gg\n",
    "\n",
    "# User input. Counts to 10.\n",
    "v_bool_exit = 0\n",
    "\n",
    "# In case AddressToCoord is called without a person to attach\n",
    "v_row_counter = 0\n",
    "\n",
    "# Empty DataFrame to write unattached coords to\n",
    "v_df_locations = pd.DataFrame()\n",
    "v_df_location_attachments = pd.DataFrame(pd.read_csv(\"Pemmer_Works_Matches.csv\", sep=\",\"))\n",
    "\n",
    "\n",
    "v_geolocator = gg.Nominatim(user_agent=\"sebastian.wegerer@hotmail.com\")\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Returs coords for an address. \n",
    "# Data can be attached to a person in the main work spreadsheet\n",
    "def AddressToCoord(p_address, p_person=None):    \n",
    "    \n",
    "    l_location = v_geolocator.geocode(p_address)\n",
    "    l_new_lat = l_location.latitude\n",
    "    l_new_long = l_location.longitude \n",
    "    \n",
    "    # Creates a row in the DataFrame.\n",
    "    # DataFrame is printed to csv after user input is closed.\n",
    "    if p_person == None:\n",
    "        v_df_locations.loc[v_row_counter, 'lat'] = l_new_lat\n",
    "        v_df_locations.loc[v_row_counter, 'long'] = l_new_long\n",
    "        v_df_locations.loc[v_row_counter, 'address'] = p_address\n",
    "    else:\n",
    "        # Data has to attached to person\n",
    "        # Checks for matches.\n",
    "        if any(v_df_location_attachments.loc[v_df_location_attachments['varchar Name'] == (p_person), 'varchar Name']):\n",
    "            v_df_location_attachments.loc[v_df_location_attachments['varchar Name'] == (p_person), 'lat'] = l_new_lat\n",
    "            v_df_location_attachments.loc[v_df_location_attachments['varchar Name'] == (p_person), 'long'] = l_new_long\n",
    "            v_df_location_attachments.loc[v_df_location_attachments['varchar Name'] == (p_person), 'address'] = p_address\n",
    "        else:\n",
    "            print(\"Warning E05: No one found with the name: \" + p_person + \". Coords for: \" + p_address + \" are not saved!\") \n",
    "         \n",
    "        \n",
    "        \n",
    "# ----------------------------------------------------------       \n",
    "\n",
    "\n",
    "while v_bool_exit == 0:\n",
    "    l_new_address = input(\"Exit with: -1- or enter the address you would like to check: \")\n",
    "    \n",
    "    if l_new_address == \"1\":\n",
    "        v_bool_exit = 1\n",
    "    else:\n",
    "        l_person = input(\"Skip with: -2- or enter name to attach: \")\n",
    "        \n",
    "        if l_person == \"2\":\n",
    "            AddressToCoord(l_new_address)\n",
    "            v_row_counter = v_row_counter + 1\n",
    "        else:\n",
    "            AddressToCoord(l_new_address, l_person)\n",
    "\n",
    "        \n",
    "v_df_locations.to_csv(\"Address_Spreadsheet.csv\", index=False)  \n",
    "v_df_location_attachments.to_csv(\"Pemmer_Works_Matches.csv\", index=False)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aeb341-5bef-47aa-a235-656134be0afd",
   "metadata": {},
   "source": [
    "## 4) Sort csv(s)\n",
    "\n",
    "\n",
    "Simple Input for file and optional column to sort ascending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85849490-230b-4dde-b59d-8929be7e7fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Exit with: -1- or enter the name of the file you would like to sort:  Pemmer_Works_Spreadsheet\n",
      "Skip with: -2- or enter column to sort by:  varchar Name\n",
      "Exit with: -1- or enter the name of the file you would like to sort:  1\n"
     ]
    }
   ],
   "source": [
    "v_bool_exit = 0\n",
    "\n",
    "while v_bool_exit == 0:\n",
    "    l_file = input(\"Exit with: -1- or enter the name of the file you would like to sort: \")\n",
    "    \n",
    "    if l_file == \"1\":\n",
    "        v_bool_exit = 1\n",
    "    else:\n",
    "        v_df_sort = pd.DataFrame(pd.read_csv(\"Pemmer_Works_Matches.csv\", sep=\",\"))\n",
    "\n",
    "        \n",
    "        l_column = input(\"Skip with: -2- or enter column to sort by: \")\n",
    "        \n",
    "        if l_column == \"2\":\n",
    "            v_df_sorted = v_df_sort.sort_values(by='varchar_Name', ascending=True, na_position='first')\n",
    "\n",
    "            AddressToCoord(l_file)\n",
    "        else:\n",
    "            v_df_sorted = v_df_sort.sort_values(by=l_column, ascending=True, na_position='first')\n",
    "\n",
    "  \n",
    "        v_df_sorted.to_csv(l_file + \".csv\", index=False)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef64d0d-c8c5-4c42-9bd1-7e62772f7060",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7ea85230-3d14-40e2-a8bc-1797ebdd7464",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
